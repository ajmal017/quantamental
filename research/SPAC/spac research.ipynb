{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import time\n",
    "import smtplib, ssl\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import COMMASPACE, formatdate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Company  Symbol    IPO Date  \\\n",
      "0                 8i Enterprises Acquisition Corp   JFKKU   3/28/2019   \n",
      "1               Acamar Partners Acquisition Corp.    ACAM   2/22/2019   \n",
      "2               Ace Convergence Acquisition Corp.  ACEV.U   7/28/2020   \n",
      "3                           AGBA Acquisition Ltd.    AGBA   5/14/2019   \n",
      "4                Alberton Acquisition Corporation    ALAC  10/24/2018   \n",
      "5                 Alussa Energy Acquisition Corp.    ALUS  11/26/2019   \n",
      "6                          AMCI Acquisition Corp.    AMCI  11/16/2018   \n",
      "7    Amplitude Healthcare Acquisition Corporation    AMHC  11/20/2019   \n",
      "8                    Andina Acquisition Corp. III    ANDA   1/29/2019   \n",
      "9         Apex Technology Acquisition Corporation    APXT   9/17/2019   \n",
      "10                        Artius Acquisition Inc.    AACQ   7/14/2020   \n",
      "11              ARYA Sciences Acquisition Corp II    ARYB    6/5/2020   \n",
      "12             ARYA Sciences Acquisition Corp III    ARYA    8/7/2020   \n",
      "13            Ascendant Digital Acquisition Corp.    ACND   7/24/2020   \n",
      "14             B. Riley Principal Merger Corp. II    BMRG   5/20/2020   \n",
      "15                         BCTG Acquisition Corp.    BCTG    9/3/2020   \n",
      "16            Big Rock Partners Acquisition Corp.    BRPA  11/20/2017   \n",
      "17                         BowX Acquisition Corp.   BOWXU    8/5/2020   \n",
      "18              Brilliant Acquisition Corporation    BRLI   6/24/2020   \n",
      "19                   Broadstone Acquisition Corp.   BSN.U   9/11/2020   \n",
      "20    Burgundy Technology Acquisition Corporation   BTAQU   8/27/2020   \n",
      "21      Capstar Special Purpose Acquisition Corp.    CPSR    7/2/2020   \n",
      "22              CC Neuberger Principal Holdings I    PCPL   4/24/2020   \n",
      "23             CC Neuberger Principal Holdings II    PRPB   7/31/2020   \n",
      "24                   CF Finance Acquisition Corp.    CFFA  12/13/2018   \n",
      "25                CF Finance Acquisition Corp. II    CFII   8/27/2020   \n",
      "26         Chardan Healthcare Acquisition 2 Corp.  CHAQ.U   4/24/2020   \n",
      "27                               CHP Merger Corp.    CHPM  11/22/2019   \n",
      "28                      Churchill Capital Corp II    CCC2   6/27/2019   \n",
      "29                     Churchill Capital Corp III    CCXX   2/14/2020   \n",
      "..                                            ...     ...         ...   \n",
      "138    Schultze Special Purpose Acquisition Corp.    SAMA  12/11/2018   \n",
      "139                                    SCVX Corp.    SCVX   1/24/2020   \n",
      "140                Silver Spike Acquisition Corp.    SSPK    8/8/2019   \n",
      "141   Social Capital Hedosophia Holdings Corp. II    IPOB   4/28/2020   \n",
      "142  Social Capital Hedosophia Holdings Corp. III    IPOC   4/22/2020   \n",
      "143               Software Acquisition Group Inc.    SAQN  11/20/2019   \n",
      "144            Software Acquisition Group Inc. II   SAIIU   9/15/2020   \n",
      "145                   South Mountain Merger Corp.    SMMC   6/20/2019   \n",
      "146              Spartan Energy Acquisition Corp.    SPAQ   8/10/2018   \n",
      "147                 Stable Road Acquisition Corp.    SRAC   11/8/2019   \n",
      "148             Star Peak Energy Transition Corp.  STPK.U   8/18/2020   \n",
      "149             Starboard Value Acquisition Corp.   SVACU   9/10/2020   \n",
      "150   Sustainable Opportunities Acquisition Corp.    SOAC    5/6/2020   \n",
      "151     Switchback Energy Acquisition Corporation     SBE   7/26/2019   \n",
      "152                    Tailwind Acquisition Corp.  TWND.U    9/4/2020   \n",
      "153                     Tenzing Acquisition Corp.    TZAC   8/21/2018   \n",
      "154           Thunder Bridge Acquisition II, Ltd.    THBR    8/9/2019   \n",
      "155                    Tortoise Acquisition Corp.    SHLL   2/28/2019   \n",
      "156                 Tortoise Acquisition Corp. II  SNPR.U   9/11/2020   \n",
      "157               Tottenham Acquisition I Limited    TOTA    8/2/2018   \n",
      "158                      Trebia Acquisition Corp.    TREB   6/17/2020   \n",
      "159                    Trident Acquisitions Corp.    TDAC   5/30/2018   \n",
      "160                       Trine Acquisition Corp.    TRNE   3/15/2019   \n",
      "161                         Tuscan Holdings Corp.    THCB    3/5/2019   \n",
      "162                      Tuscan Holdings Corp. II    THCA   7/12/2019   \n",
      "163                    TWC Tech Holdings II Corp.   TWCTU   9/11/2020   \n",
      "164                    Union Acquisition Corp. II    LATN  10/18/2019   \n",
      "165         Vistas Media Acquisition Company Inc.    VMAC    8/7/2020   \n",
      "166               Yucaipa Acquisition Corporation     YAC    8/4/2020   \n",
      "167                         Yunhong International   ZGYHU   2/13/2020   \n",
      "\n",
      "    Liquidation Date ?Trust Acct/Share   Trust Account  Unit Specs  \\\n",
      "0          9/30/2020            $10.30     $59,246,412     U=S+W+R   \n",
      "1          2/26/2021            $10.18    $311,011,126     U=S+W/3   \n",
      "2          1/30/2022            $10.00    $230,000,000     U=S+W/2   \n",
      "3         11/16/2020            $10.28     $47,307,540     U=S+W+R   \n",
      "4         10/26/2020            $10.60     $14,993,648     U=S+W+R   \n",
      "5         11/29/2021            $10.08    $289,642,871     U=S+W/2   \n",
      "6         10/20/2020            $10.24    $152,758,330       U=S+W   \n",
      "7         11/22/2021            $10.03    $100,343,160     U=S+W/2   \n",
      "8         10/31/2020            $10.24     $66,528,226     U=S+W+R   \n",
      "9          9/19/2021            $10.07    $352,264,484     U=S+W/2   \n",
      "10         7/16/2022            $10.00    $724,500,000     U=S+W/3   \n",
      "11          6/9/2022            $10.00    $149,486,587     U=S+W/3   \n",
      "12         8/11/2022            $10.00    $149,500,000         U=S   \n",
      "13         7/28/2022            $10.00    $414,000,000     U=S+W/2   \n",
      "14        11/22/2021            $10.10    $176,738,914     U=S+W/2   \n",
      "15          9/8/2022            $10.00    $166,750,000         U=S   \n",
      "16        12/23/2020            $10.76      $6,243,841   U=S+R+W/2   \n",
      "17          8/7/2022            $10.00    $483,000,000     U=S+W/3   \n",
      "18         6/26/2021            $10.00     $46,000,107     U=S+W+R   \n",
      "19         9/15/2022            $10.00   $300,000,000*     U=S+W/2   \n",
      "20          3/2/2022            $10.05   $301,500,000*     U=S+W/2   \n",
      "21          7/7/2022            $10.00    $276,000,000     U=S+W/2   \n",
      "22         4/28/2022            $10.00    $414,028,653     U=S+W/3   \n",
      "23          8/4/2022            $10.00    $828,000,000     U=S+W/4   \n",
      "24        12/17/2020            $10.36    $286,565,390  U=S+(3/4)W   \n",
      "25         8/31/2022            $10.00   $500,000,000*     U=S+W/3   \n",
      "26         4/28/2022            $10.00     $86,237,990       U=S+W   \n",
      "27        11/26/2021            $10.06    $301,735,733     U=S+W/2   \n",
      "28          7/1/2021            $10.10    $697,031,785     U=S+W/3   \n",
      "29         2/19/2022            $10.03  $1,103,757,008     U=S+W/4   \n",
      "..               ...               ...             ...         ...   \n",
      "138        9/30/2020            $10.22    $132,448,821       U=S+W   \n",
      "139        1/28/2022            $10.02    $230,523,688     U=S+W/2   \n",
      "140        2/12/2021            $10.16    $254,070,734     U=S+W/2   \n",
      "141        4/30/2022            $10.00    $414,025,917     U=S+W/3   \n",
      "142        4/24/2022            $10.00    $828,064,246     U=S+W/3   \n",
      "143        5/22/2021            $10.04    $150,053,919     U=S+W/2   \n",
      "144        3/17/2022            $10.00   $150,000,000*     U=S+W/2   \n",
      "145        6/24/2021            $10.10    $252,466,180     U=S+W/2   \n",
      "146        2/14/2021            $10.32    $568,756,787     U=S+W/3   \n",
      "147        5/12/2021            $10.05    $173,377,731     U=S+W/2   \n",
      "148        8/20/2022            $10.00    $383,585,040     U=S+W/3   \n",
      "149        9/14/2022            $10.00   $360,000,000*    U=S+W/3*   \n",
      "150        11/8/2021            $10.00    $300,041,768     U=S+W/2   \n",
      "151        7/30/2021            $10.08    $316,623,539     U=S+W/3   \n",
      "152         9/9/2022            $10.00    $334,215,700     U=S+W/2   \n",
      "153        9/28/2020            $10.71     $34,219,205       U=S+W   \n",
      "154        8/13/2021            $10.13    $349,565,514     U=S+W/2   \n",
      "155         3/4/2021            $10.17    $236,860,741     U=S+W/2   \n",
      "156        9/15/2022            $10.00   $345,000,000*     U=S+W/4   \n",
      "157        11/6/2020            $10.78     $25,276,693     U=S+W+R   \n",
      "158        6/19/2022            $10.00    $517,500,000     U=S+W/3   \n",
      "159        12/1/2020            $10.76     $62,286,780       U=S+W   \n",
      "160        3/19/2021            $10.18    $305,572,817     U=S+W/2   \n",
      "161        12/7/2020            $10.22    $281,882,841       U=S+W   \n",
      "162        4/16/2021            $10.12    $174,523,771     U=S+W/2   \n",
      "163        9/15/2022            $10.00    $600,000,000     U=S+W/3   \n",
      "164        4/22/2021            $10.06    $201,285,014       U=S+W   \n",
      "165         8/7/2021            $10.00   $100,000,000*       U=S+W   \n",
      "166         8/6/2022            $10.00    $345,000,000     U=S+W/3   \n",
      "167        2/18/2021             $9.84     $67,902,176   U=S+R+W/2   \n",
      "\n",
      "    Warrant Specs Merger Target?  \\\n",
      "0      W=S/2@11.5            Yes   \n",
      "1        W=S@11.5             No   \n",
      "2        W=S@11.5             No   \n",
      "3      W=S/2@11.5             No   \n",
      "4      W=S/2@11.5             No   \n",
      "5        W=S@11.5             No   \n",
      "6        W=S@11.5             No   \n",
      "7        W=S@11.5             No   \n",
      "8        W=S@11.5             No   \n",
      "9        W=S@11.5             No   \n",
      "10       W=S@11.5             No   \n",
      "11       W=S@11.5            Yes   \n",
      "12            NaN             No   \n",
      "13       W=S@11.5             No   \n",
      "14       W=S@11.5            Yes   \n",
      "15            NaN             No   \n",
      "16       W=S@11.5             No   \n",
      "17       W=S@11.5             No   \n",
      "18       W=S@11.5             No   \n",
      "19       W=S@11.5             No   \n",
      "20       W=S@11.5             No   \n",
      "21       W=S@11.5             No   \n",
      "22       W=S@11.5             No   \n",
      "23       W=S@11.5             No   \n",
      "24       W=S@11.5            Yes   \n",
      "25       W=S@11.5             No   \n",
      "26     W=S/2@11.5             No   \n",
      "27       W=S@11.5             No   \n",
      "28       W=S@11.5             No   \n",
      "29       W=S@11.5            Yes   \n",
      "..            ...            ...   \n",
      "138      W=S@11.5            Yes   \n",
      "139      W=S@11.5             No   \n",
      "140      W=S@11.5             No   \n",
      "141      W=S@11.5             No   \n",
      "142      W=S@11.5             No   \n",
      "143      W=S@11.5            Yes   \n",
      "144      W=S@11.5             No   \n",
      "145      W=S@11.5             No   \n",
      "146      W=S@11.5            Yes   \n",
      "147      W=S@11.5             No   \n",
      "148      W=S@11.5             No   \n",
      "149      W=S@11.5             No   \n",
      "150      W=S@11.5             No   \n",
      "151      W=S@11.5             No   \n",
      "152      W=S@11.5             No   \n",
      "153      W=S@11.5            Yes   \n",
      "154      W=S@11.5             No   \n",
      "155      W=S@11.5            Yes   \n",
      "156      W=S@11.5             No   \n",
      "157    W=S/2@11.5            Yes   \n",
      "158      W=S@11.5             No   \n",
      "159      W=S@11.5             No   \n",
      "160      W=S@11.5            Yes   \n",
      "161      W=S@11.5             No   \n",
      "162      W=S@11.5             No   \n",
      "163      W=S@11.5             No   \n",
      "164      W=S@11.5             No   \n",
      "165      W=S@11.5             No   \n",
      "166      W=S@11.5             No   \n",
      "167      W=S@11.5             No   \n",
      "\n",
      "                                       Intended Sector  \n",
      "0                                                 Asia  \n",
      "1                                    Consumer & retail  \n",
      "2         IT infrastructure software and semiconductor  \n",
      "3    Healthcare, education, entertainment and finan...  \n",
      "4                                        Not specified  \n",
      "5                                               Energy  \n",
      "6    Natural Resources and Mining Equipment, Techno...  \n",
      "7                                           Healthcare  \n",
      "8    Countries in Latin America with stable politic...  \n",
      "9                     Software and internet technology  \n",
      "10                       Technology enabled businesses  \n",
      "11   Life sciences and medical technologies in Nort...  \n",
      "12   Life sciences and medical technologies in Nort...  \n",
      "13   Interactive (digital) entertainment, film/tele...  \n",
      "14                                       Not specified  \n",
      "15           Biotechnology in North America and Europe  \n",
      "16   Senior housing and care industry in the United...  \n",
      "17                                                 TMT  \n",
      "18                                 Asia-pacific region  \n",
      "19     Europe and UK (Coronavirus-stressed businesses)  \n",
      "20                                          Technology  \n",
      "21                         Consumer, Healthcare or TMT  \n",
      "22        Financial, technology, and business services  \n",
      "23                                       Not specified  \n",
      "24          Financial services or real estate services  \n",
      "25   Financial services, healthcare, real estate se...  \n",
      "26                         Healthcare in North America  \n",
      "27                     Healthcare in the United States  \n",
      "28                                       Not specified  \n",
      "29                                       Not specified  \n",
      "..                                                 ...  \n",
      "138  Businesses that have experienced a financial r...  \n",
      "139                                      Cybersecurity  \n",
      "140                                           Cannabis  \n",
      "141                               Technology in the US  \n",
      "142                          Technology outside the US  \n",
      "143                                           Software  \n",
      "144                                           Software  \n",
      "145                                            Fintech  \n",
      "146                            Energy in North America  \n",
      "147  Cannabis-adjacent (businesses that do not \"tou...  \n",
      "148  Energy Transition (renewables, bio fuels, hydr...  \n",
      "149  Technology, healthcare, consumer, industrials ...  \n",
      "150                                  Sustainable (ESG)  \n",
      "151                            Energy in North America  \n",
      "152  Consumer internet, digital media and marketing...  \n",
      "153                                              India  \n",
      "154                                 Financial services  \n",
      "155                            Energy in North America  \n",
      "156          Broad energy transition or sustainability  \n",
      "157  TMT, education, e-commerce, health-care and co...  \n",
      "158  Financial services, technology, software, data...  \n",
      "159  Oil and gas or other natural resources in East...  \n",
      "160  Technology, consumer, and/or media and communi...  \n",
      "161                                           Cannabis  \n",
      "162                                           Cannabis  \n",
      "163  Technology and technology-enabled services sec...  \n",
      "164                                      Latin America  \n",
      "165                            Media and entertainment  \n",
      "166                                      Not specified  \n",
      "167                             Asia (excluding China)  \n",
      "\n",
      "[168 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  168 of 168 completed\n",
      "\n",
      "34 Failed downloads:\n",
      "- PTK.U: No data found, symbol may be delisted\n",
      "- ACEV.U: No data found, symbol may be delisted\n",
      "- CHAQ.U: No data found, symbol may be delisted\n",
      "- LEAP.U: No data found, symbol may be delisted\n",
      "- SBG.U: No data found, symbol may be delisted\n",
      "- FAII.U: No data found, symbol may be delisted\n",
      "- STPK.U: No data found, symbol may be delisted\n",
      "- BFT.U: No data found, symbol may be delisted\n",
      "- CLA.U: No data found, symbol may be delisted\n",
      "- HZAC.U: No data found, symbol may be delisted\n",
      "- BSN.U: No data found, symbol may be delisted\n",
      "- GOAC.U: No data found, symbol may be delisted\n",
      "- NPAU: No data found, symbol may be delisted\n",
      "- TWND.U: No data found, symbol may be delisted\n",
      "- GSAH.U: No data found, symbol may be delisted\n",
      "- EAGL6: No data found, symbol may be delisted\n",
      "- AONE.U: No data found, symbol may be delisted\n",
      "- NSH.U: No data found, symbol may be delisted\n",
      "- DGNR.U: No data found, symbol may be delisted\n",
      "- NGA.U: No data found, symbol may be delisted\n",
      "- SNPR.U: No data found, symbol may be delisted\n",
      "- DFHT: No data found, symbol may be delisted\n",
      "- PIAI.U: No data found, symbol may be delisted\n",
      "- RBAC.U: No data found, symbol may be delisted\n",
      "- IPV.U: No data found, symbol may be delisted\n",
      "- FST.U: No data found, symbol may be delisted\n",
      "- CCC2: No data found, symbol may be delisted\n",
      "- CCIV: No data found, symbol may be delisted\n",
      "- FTOC: No data found, symbol may be delisted\n",
      "- DMYD.U: No data found, symbol may be delisted\n",
      "- PRPB: No data found, symbol may be delisted\n",
      "- CRHC.U: No data found, symbol may be delisted\n",
      "- CFII: No data found, symbol may be delisted\n",
      "- YAC: No data found for this date range, symbol may be delisted\n",
      "           Adj Close                                                          \\\n",
      "                ACAM   AGBA   ALAC  ALUS   AMCI  AMHC    ANDA    APXT   ARYA   \n",
      "Date                                                                           \n",
      "2020-09-11     10.25  10.30  10.66  9.92  10.38  9.99  10.225  10.250  10.90   \n",
      "2020-09-14     10.20  10.30  10.78  9.90  10.38  9.97  10.250  10.225  10.90   \n",
      "2020-09-15     10.25  10.30  10.78  9.93  10.36  9.93  10.212  10.180  10.90   \n",
      "2020-09-16     10.36  10.35  10.78  9.93  10.55  9.89  10.210  10.200  10.81   \n",
      "2020-09-17     10.37  10.35  10.73  9.93  10.34  9.90  10.210  10.740  10.75   \n",
      "\n",
      "                    ...    Volume                                          \\\n",
      "              ARYB  ...      THBR  THCA   THCB   TOTA       TREB     TRNE   \n",
      "Date                ...                                                     \n",
      "2020-09-11  10.350  ...   66900.0     0   7200   2400  1165000.0  2890900   \n",
      "2020-09-14  10.450  ...  105000.0   400  16200   3600    47000.0  3069200   \n",
      "2020-09-15  10.900  ...  100800.0   600   4700   3100    72600.0  1477100   \n",
      "2020-09-16  11.240  ...   77400.0   500   5400  29600    22800.0   877500   \n",
      "2020-09-17  11.054  ...    4700.0  4000  65700    900    19400.0  1455600   \n",
      "\n",
      "                                                \n",
      "              TZAC     VMAC       WPF    ZGYHU  \n",
      "Date                                            \n",
      "2020-09-11       0  30500.0  109300.0      0.0  \n",
      "2020-09-14     400   5000.0  160000.0   2775.0  \n",
      "2020-09-15  353000   5500.0  237800.0  11000.0  \n",
      "2020-09-16   64400  24100.0  432300.0   4102.0  \n",
      "2020-09-17    3700   8000.0  135800.0   8598.0  \n",
      "\n",
      "[5 rows x 720 columns]\n"
     ]
    }
   ],
   "source": [
    "spac_info = load_spac_info(\"/Users/ZhenxinLei/MyWork/quantamental/spac/active_spacs_clean.csv\")\n",
    "tickers = list(spac_info['Symbol'])\n",
    "price = load_hist_data(tickers)\n",
    "print(price.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spac_info(path_to_csv=\"active_spacs_clean.csv\"):\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def load_hist_data(tickers, start=None, end=None, interval='1d',valid_data_window= 10):\n",
    "    price_df =None\n",
    "    if start is None or end is None:\n",
    "        price_df = yf.download(tickers, period='1Y', interval = interval)\n",
    "    else:\n",
    "        price_df = yf.download(tickers, start,end, interval = interval)\n",
    "        \n",
    "    invalid_tickers =price_df['Close'].iloc[-valid_data_window-1].isnull()\n",
    "    invalid_tickers = invalid_tickers[invalid_tickers==True]\n",
    "\n",
    "    price_df = price_df.drop(invalid_tickers.index.tolist(), axis=1, level=1)\n",
    "\n",
    "    return price_df\n",
    "\n",
    "'''\n",
    "return dataframe columns name like \"[('col_1', 'ticker_1'),('col_1','ticker_2'),...]\"\n",
    "'''\n",
    "def gen_factor_1_df(price_df,close_col='Close',volume_col = 'Volume', look_back=10, ma_window = 10):\n",
    "    df = pd.DataFrame(index = price_df.index)\n",
    "    \n",
    "    rolling_mean=price_df.xs(close_col, axis=1,level=0,drop_level=False).rolling(window = ma_window).mean()\n",
    "    #return_cols = rolling_mean/rolling_mean.shift(look_back)-1\n",
    "    close_price = price.xs(close_col, axis=1,level=0,drop_level=False)\n",
    "    return_cols = close_price/rolling_mean.shift(look_back)-1\n",
    "    return_cols =return_cols.rename(columns={close_col:'price_chg_pct'})\n",
    "    df = df.join(return_cols)\n",
    "    \n",
    "    #yesterday return \n",
    "    close_price = price.xs(close_col, axis=1,level=0,drop_level=False)\n",
    "    return_cols = close_price/close_price.shift(1)-1\n",
    "    return_cols =return_cols.rename(columns={close_col:'ytday_price_chg_pct'})\n",
    "    \n",
    "    df = df.join(return_cols)\n",
    "    \n",
    "    #print(df.columns)\n",
    "    \n",
    "    vol_rolling_mean=price_df.xs(volume_col, axis=1,level=0,drop_level=False).rolling(window = ma_window).mean()\n",
    "    volume = price.xs(volume_col, axis=1,level=0,drop_level=False)\n",
    "    vol_chg_pct = volume/vol_rolling_mean.shift(look_back)-1\n",
    "    vol_chg_pct =vol_chg_pct.rename(columns={volume_col:'vol_chg_pct'})\n",
    "    df = df.join(vol_chg_pct)\n",
    "    \n",
    "    avg_price =price_df[['Close','Open','High','Low']].mean(axis=1,level=1)\n",
    "    volume = price_df['Volume']\n",
    "    volume_in_usd =avg_price*volume\n",
    "    #print(volume_in_usd.columns,avg_price.columns )\n",
    "    for col_name in volume_in_usd.columns:\n",
    "        volume_in_usd = volume_in_usd.rename(columns={col_name:('volume_in_usd',col_name)})\n",
    "    df = df.join(volume_in_usd)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_fct1_filter1_tickers(tickers, fct1_df):\n",
    "    abnormal_tickers=[]\n",
    "    for ticker in tickers:\n",
    "        is_abnormal_return =fct1_df[('price_chg_pct',ticker)].iloc[-1]> 0.05\n",
    "        is_abnormal_volume = fct1_df[('vol_chg_pct',ticker)].iloc[-1]>0.30\n",
    "        if is_abnormal_return and is_abnormal_volume:\n",
    "            #print( ticker, is_abnormal_return)\n",
    "            abnormal_tickers.append(ticker)\n",
    "    \n",
    "    return abnormal_tickers\n",
    "\n",
    "\n",
    "def get_fct1_filter2_tickers(tickers, fct1_df):\n",
    "    abnormal_tickers=[]\n",
    "    for ticker in tickers:\n",
    "        is_abnormal_return = (fct1_df[('price_chg_pct',ticker)].iloc[-1]<=0.03) & (fct1_df[('price_chg_pct',ticker)].iloc[-1]>=-0.03)\n",
    "        is_abnormal_volume = fct1_df[('vol_chg_pct',ticker)].iloc[-1]>0.50\n",
    "        if is_abnormal_return and is_abnormal_volume:\n",
    "            #print( ticker, is_abnormal_return)\n",
    "            abnormal_tickers.append(ticker)\n",
    "    \n",
    "    return abnormal_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ACAM</th>\n",
       "      <th>AGBA</th>\n",
       "      <th>ALAC</th>\n",
       "      <th>ALUS</th>\n",
       "      <th>AMCI</th>\n",
       "      <th>AMHC</th>\n",
       "      <th>ANDA</th>\n",
       "      <th>APXT</th>\n",
       "      <th>ARYA</th>\n",
       "      <th>ARYB</th>\n",
       "      <th>...</th>\n",
       "      <th>THBR</th>\n",
       "      <th>THCA</th>\n",
       "      <th>THCB</th>\n",
       "      <th>TOTA</th>\n",
       "      <th>TREB</th>\n",
       "      <th>TRNE</th>\n",
       "      <th>TZAC</th>\n",
       "      <th>VMAC</th>\n",
       "      <th>WPF</th>\n",
       "      <th>ZGYHU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-11</th>\n",
       "      <td>10.25</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.66</td>\n",
       "      <td>9.92</td>\n",
       "      <td>10.38</td>\n",
       "      <td>9.99</td>\n",
       "      <td>10.225</td>\n",
       "      <td>10.250</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.350</td>\n",
       "      <td>...</td>\n",
       "      <td>66900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7200</td>\n",
       "      <td>2400</td>\n",
       "      <td>1165000.0</td>\n",
       "      <td>2890900</td>\n",
       "      <td>0</td>\n",
       "      <td>30500.0</td>\n",
       "      <td>109300.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>10.20</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.78</td>\n",
       "      <td>9.90</td>\n",
       "      <td>10.38</td>\n",
       "      <td>9.97</td>\n",
       "      <td>10.250</td>\n",
       "      <td>10.225</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.450</td>\n",
       "      <td>...</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>400</td>\n",
       "      <td>16200</td>\n",
       "      <td>3600</td>\n",
       "      <td>47000.0</td>\n",
       "      <td>3069200</td>\n",
       "      <td>400</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>2775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>10.25</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.78</td>\n",
       "      <td>9.93</td>\n",
       "      <td>10.36</td>\n",
       "      <td>9.93</td>\n",
       "      <td>10.212</td>\n",
       "      <td>10.180</td>\n",
       "      <td>10.90</td>\n",
       "      <td>10.900</td>\n",
       "      <td>...</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>600</td>\n",
       "      <td>4700</td>\n",
       "      <td>3100</td>\n",
       "      <td>72600.0</td>\n",
       "      <td>1477100</td>\n",
       "      <td>353000</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>237800.0</td>\n",
       "      <td>11000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>10.36</td>\n",
       "      <td>10.35</td>\n",
       "      <td>10.78</td>\n",
       "      <td>9.93</td>\n",
       "      <td>10.55</td>\n",
       "      <td>9.89</td>\n",
       "      <td>10.210</td>\n",
       "      <td>10.200</td>\n",
       "      <td>10.81</td>\n",
       "      <td>11.240</td>\n",
       "      <td>...</td>\n",
       "      <td>77400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>5400</td>\n",
       "      <td>29600</td>\n",
       "      <td>22800.0</td>\n",
       "      <td>877500</td>\n",
       "      <td>64400</td>\n",
       "      <td>24100.0</td>\n",
       "      <td>432300.0</td>\n",
       "      <td>4102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-17</th>\n",
       "      <td>10.37</td>\n",
       "      <td>10.35</td>\n",
       "      <td>10.73</td>\n",
       "      <td>9.93</td>\n",
       "      <td>10.34</td>\n",
       "      <td>9.90</td>\n",
       "      <td>10.210</td>\n",
       "      <td>10.740</td>\n",
       "      <td>10.75</td>\n",
       "      <td>11.054</td>\n",
       "      <td>...</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>65700</td>\n",
       "      <td>900</td>\n",
       "      <td>19400.0</td>\n",
       "      <td>1455600</td>\n",
       "      <td>3700</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>135800.0</td>\n",
       "      <td>8598.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 720 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Adj Close                                                          \\\n",
       "                ACAM   AGBA   ALAC  ALUS   AMCI  AMHC    ANDA    APXT   ARYA   \n",
       "Date                                                                           \n",
       "2020-09-11     10.25  10.30  10.66  9.92  10.38  9.99  10.225  10.250  10.90   \n",
       "2020-09-14     10.20  10.30  10.78  9.90  10.38  9.97  10.250  10.225  10.90   \n",
       "2020-09-15     10.25  10.30  10.78  9.93  10.36  9.93  10.212  10.180  10.90   \n",
       "2020-09-16     10.36  10.35  10.78  9.93  10.55  9.89  10.210  10.200  10.81   \n",
       "2020-09-17     10.37  10.35  10.73  9.93  10.34  9.90  10.210  10.740  10.75   \n",
       "\n",
       "                    ...    Volume                                          \\\n",
       "              ARYB  ...      THBR  THCA   THCB   TOTA       TREB     TRNE   \n",
       "Date                ...                                                     \n",
       "2020-09-11  10.350  ...   66900.0     0   7200   2400  1165000.0  2890900   \n",
       "2020-09-14  10.450  ...  105000.0   400  16200   3600    47000.0  3069200   \n",
       "2020-09-15  10.900  ...  100800.0   600   4700   3100    72600.0  1477100   \n",
       "2020-09-16  11.240  ...   77400.0   500   5400  29600    22800.0   877500   \n",
       "2020-09-17  11.054  ...    4700.0  4000  65700    900    19400.0  1455600   \n",
       "\n",
       "                                                \n",
       "              TZAC     VMAC       WPF    ZGYHU  \n",
       "Date                                            \n",
       "2020-09-11       0  30500.0  109300.0      0.0  \n",
       "2020-09-14     400   5000.0  160000.0   2775.0  \n",
       "2020-09-15  353000   5500.0  237800.0  11000.0  \n",
       "2020-09-16   64400  24100.0  432300.0   4102.0  \n",
       "2020-09-17    3700   8000.0  135800.0   8598.0  \n",
       "\n",
       "[5 rows x 720 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZhenxinLei/riverrocktech/lib/python3.6/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALAC', 'ALUS', 'BRLI', 'CCAC', 'CIIC', 'DFPH', 'ESSC', 'GRSVU', 'JIH', 'KBLM', 'LOAC', 'LSAC', 'MFAC', 'MLAC', 'MNCL', 'ROCH', 'SFTW', 'ZGYHU']\n"
     ]
    }
   ],
   "source": [
    "df = gen_factor_1_df(price)\n",
    "df.tail()\n",
    "abnormal_tickers = get_fct1_filter2_tickers(price['Close'].columns, df)\n",
    "\n",
    "to_send ={}\n",
    "for ticker in abnormal_tickers:\n",
    "    \n",
    "    tmp = pd.DataFrame()\n",
    "    to_send[ticker]=tmp\n",
    "    #tmp = df[[('price_chg_pct',ticker), ('vol_chg_pct',ticker),('volume_in_usd',ticker)]]\n",
    "    tmp['price ma change(%)']= (df[('price_chg_pct',ticker)]*100).apply(lambda x: '{:,.2f}%'.format(x))\n",
    "    tmp['ytday price change(%)']= (df[('ytday_price_chg_pct',ticker)]*100).apply(lambda x: '{:,.2f}%'.format(x))\n",
    "    tmp['volume change(%)'] =(df[('vol_chg_pct',ticker)]*100).apply(lambda x: '{:,.2f}%'.format(x))\n",
    "    tmp['volume USD($MM)'] = (df[('volume_in_usd',ticker)]/1000000).apply(lambda x: '${:,.2f}MM'.format(x))\n",
    "    tmp['Close']=price['Close'][ticker].apply(lambda x: '{:,.2f}'.format(x))\n",
    "    \n",
    "    #has_target = (spac_info[spac_info['Symbol']==ticker]['Merger Target?']).values\n",
    "    #ipo_date = spac_info[spac_info['Symbol']==ticker]['IPO Date'].values\n",
    "    liq_date = spac_info[spac_info['Symbol']==ticker][['Symbol','Merger Target?','IPO Date', 'Liquidation Date']]\n",
    "    #print(liq_date)\n",
    "    #print(tmp.tail(5))\n",
    "    #print('\\n')\n",
    "print(abnormal_tickers)   \n",
    "#print(to_send['ACAM'].tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def send_email(to_send):\n",
    "    filename ='sample.txt'\n",
    "    file_full_name = './'+filename\n",
    "    with open(file_full_name,'w') as outfile:\n",
    "        for ticker, df  in to_send.items():\n",
    "            outfile.write('\\n======== %s ========\\n'%(ticker))\n",
    "            header = spac_info[spac_info['Symbol']==ticker][['Symbol','Merger Target?','IPO Date', 'Liquidation Date']]\n",
    "            header.to_string(outfile)\n",
    "            outfile.write('\\n')\n",
    "            to_send[ticker].tail(10).to_string(outfile)\n",
    "            outfile.write('\\n\\n')\n",
    "            \n",
    "    try:\n",
    "        server = smtplib.SMTP(\"smtp.gmail.com\",\"587\")\n",
    "        #self.server.ehlo() # Can be omitted\n",
    "        server.starttls()\n",
    "        #self.server.ehlo() # Can be omitted\n",
    "        server.login(\"heytechnologies@gmail.com\", 'Zhxlei87!')\n",
    "\n",
    "        message = MIMEMultipart()\n",
    "        message['From'] = \"heytechnologies@gmail.com\"\n",
    "        message['Bcc'] = COMMASPACE.join(['zhenxinlei@gmail.com'])\n",
    "        message['Subject']='test sample'\n",
    "\n",
    "        sent=0\n",
    "        retry=0\n",
    "        while sent==0:\n",
    "            try:\n",
    "                \n",
    "                #filename = \"document.pdf\"  # In same directory as script\n",
    "\n",
    "                # Open PDF file in binary mode\n",
    "                with open(file_full_name, \"rb\") as attachment:\n",
    "                    # Add file as application/octet-stream\n",
    "                    # Email client can usually download this automatically as attachment\n",
    "                    part = MIMEApplication(\n",
    "                        attachment.read(),\n",
    "                        Name=filename\n",
    "                    )\n",
    "\n",
    "                # Encode file in ASCII characters to send by email    \n",
    "                #encoders.encode_base64(part)\n",
    "\n",
    "                # Add header as key/value pair to attachment part\n",
    "                part['Content-Disposition'] = 'attachment; filename=\"%s\"' % (filename)\n",
    "        \n",
    "\n",
    "                # Add attachment to message and convert message to string\n",
    "                message.attach(part)\n",
    "                text = message.as_string()\n",
    "\n",
    "                server.sendmail('heytechnologies@gmail.com',['zhenxinlei@gmail.com'],text)\n",
    "                sent+=1\n",
    "            except Exception as e:\n",
    "                time.sleep(1) #TODO not good\n",
    "                retry +=1\n",
    "                if retry == 2:\n",
    "                    raise Exception (\"Failed to send Email after retry %s\"%e)\n",
    "                    break\n",
    "                #self.__logger.log(logging.WARN,\"Failed to send email: %s\"%e)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        server.quit()\n",
    "    \n",
    "send_email(to_send)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2020-09-11    10.2945\n",
      "2020-09-14    10.3115\n",
      "2020-09-15    10.3365\n",
      "2020-09-16    10.6465\n",
      "2020-09-17    11.0465\n",
      "Name: SBE, dtype: float64\n",
      "Date\n",
      "2020-09-11    10.35\n",
      "2020-09-14    10.37\n",
      "2020-09-15    10.45\n",
      "2020-09-16    13.30\n",
      "2020-09-17    14.25\n",
      "Name: SBE, dtype: float64\n",
      "Date\n",
      "2020-09-11    0.009411\n",
      "2020-09-14    0.012448\n",
      "2020-09-15    0.021755\n",
      "2020-09-16    0.301688\n",
      "2020-09-17    0.393848\n",
      "Name: SBE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rolling_mean=price.xs(['Close'], axis=1,level=0,drop_level=False).rolling(window = 10).mean()\n",
    "close_price = price.xs(['Close'], axis=1,level=0,drop_level=False)\n",
    "return_cols = close_price/rolling_mean.shift(10)-1\n",
    "print(rolling_mean['Close']['SBE'].tail(5))\n",
    "print(close_price['Close']['SBE'].tail(5))\n",
    "print(return_cols['Close']['SBE'].tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[]\n",
    "b=[1,2]\n",
    "c=[3,4]\n",
    "a.append(b)\n",
    "a.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riverrock",
   "language": "python",
   "name": "riverrock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
